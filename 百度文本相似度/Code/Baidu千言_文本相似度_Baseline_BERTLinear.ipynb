{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "1DXlS3vq5iUL"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "记得每次训练更改新的model name用以分别保存模型参数文件\n",
    "可以通过dataset id来选择三个数据集中的一个\n",
    "\"\"\"\n",
    "\n",
    "m_name = 'bertlinear_bbc_z0' # model name, bbc = 'bert-base-chinese\n",
    "dsid = 2 # dataset id = ['/bq_corpus','/lcqmc','/paws-x-zh'], 千言文本相似度比赛三个数据集是分开记分的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "WSeiAr4AqWFe"
   },
   "outputs": [],
   "source": [
    "debug = 1\n",
    "seed = 218\n",
    "\n",
    "# Model hyperparameter\n",
    "device = 'cuda'\n",
    "bert_model = 'bert-base-chinese' # 'hfl/chinese-roberta-wwm-ext'\n",
    "freeze_bert = False\n",
    "maxlen = 128\n",
    "finetune_units = 768\n",
    "dropout_rate = 0.1\n",
    "\n",
    "#　Train Hyperparameter\n",
    "bs = 200\n",
    "lr = 2e-5 #1e-3 #2e-5\n",
    "if debug:\n",
    "    epochs = 4\n",
    "    num_warmup_steps = 0\n",
    "else:\n",
    "    epochs = 8\n",
    "    num_warmup_steps = 2\n",
    "es_counts_MAX = 3\n",
    "# Postprocess hyperparameter\n",
    "thres = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ay5oQQtTrel4",
    "outputId": "7bc8c652-ea96-48c7-9f33-a006e06ca6e1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGMGp4N0roaJ",
    "outputId": "57d5bf51-ea96-4f57-81f7-2b2d2df62114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "PVEUNv1YqWFf"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import cosine\n",
    "import nltk\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "#float16和float32自动混合精度加速计算，官方文档：https://pytorch.org/docs/stable/amp.html\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.1-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.9 MB 19.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/bool_tbb/miniconda3/envs/transforem_new/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/bool_tbb/miniconda3/envs/transforem_new/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/bool_tbb/miniconda3/envs/transforem_new/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=03bb4c8737f99aa37e59104f12b1a69bcc0a48cb7694766b2607095b85b75ea7\n",
      "  Stored in directory: /home/bool_tbb/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-0.24.1 sklearn-0.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "ajTqKw9qqWFf"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    return seed\n",
    "\n",
    "seed = set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6weZKnqqBLyp"
   },
   "outputs": [],
   "source": [
    "# PATH Info\n",
    "CURR_PATH = os.getcwd()\n",
    "#ROOT_PATH = CURR_PATH + '/drive/MyDrive/Baidu_Qianyan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_PATH ='/home/bool_tbb/jupyter_notebook/CPT_SS/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "riZKNTNpqWFg",
    "outputId": "a0bfb4d2-3aaf-4406-e2c0-aa3058239cc9"
   },
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "\tfolder = os.path.exists(path)\n",
    "\tif not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "\t\tos.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "\t\tprint('---  New Model Folder: {}  ---'.format(m_name))\n",
    " \n",
    "\telse:\n",
    "\t\tprint('---  Model Dir Exsiting!  ---')\n",
    "\n",
    "def read_tsv(input_file):\n",
    "    with open(input_file,\"r\",encoding=\"utf-8\") as file:\n",
    "        lines = []\n",
    "        for line in file:\n",
    "            if len(line.strip().split(\"\\t\")) != 1:\n",
    "                lines.append(line.strip().split(\"\\t\"))\n",
    "        df = pd.DataFrame(lines)\n",
    "    return df\n",
    "\n",
    "DATASET_PATH = ['/bq_corpus','/lcqmc','/paws-x-zh']\n",
    "dataset_path = DATASET_PATH[dsid]\n",
    "#ROOT_PATH = '/content/drive/MyDrive/Baidu_Qianyan'\n",
    "path1 = '../Data'\n",
    "DATA_PATH = ['/train.tsv','/dev.tsv','/test.tsv']\n",
    "#MODEL_SAVE_PATH = ROOT_PATH + '/model' + dataset_path + '/' + m_name \n",
    "MODEL_SAVE_PATH =  '../../model/'+m_name\n",
    "#mkdir(MODEL_SAVE_PATH)     \n",
    "\n",
    "train = pd.DataFrame()\n",
    "dev = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "for data_path in DATA_PATH:\n",
    "    #PATH = ''.join([ROOT_PATH,dataset_path])\n",
    "    #PATH = ''.join([dataset_path,data_path])\n",
    "    PATH = ''.join([path1,dataset_path])\n",
    "    PATH = ''.join([PATH,dataset_path])\n",
    "    PATH = ''.join([PATH,data_path])\n",
    "    df = read_tsv(PATH)\n",
    "    if data_path == '/train.tsv':\n",
    "        train = pd.concat([train,df],axis = 0)\n",
    "    if data_path == '/dev.tsv':\n",
    "        dev = pd.concat([dev,df],axis = 0)\n",
    "    if data_path == '/test.tsv':\n",
    "        test = pd.concat([test,df],axis = 0)\n",
    "\n",
    "## bq_corpus在20746行的格式有问题，以下方法无法读取\n",
    "# train = pd.DataFrame()\n",
    "# for dataset_path in DATASET_PATH:\n",
    "#     print(dataset_path)\n",
    "#     for data_path in DATA_PATH:\n",
    "#         PATH = ''.join([ROOT_PATH,dataset_path])\n",
    "#         PATH = ''.join([PATH,data_path])\n",
    "#         read_df = pd.read_csv(PATH, header=0, delimiter='\\t')\n",
    "#         train.append(read_df)\n",
    "\n",
    "train[[2]] = train[[2]].astype(int)\n",
    "dev[[2]] = dev[[2]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  Model Dir Exsiting!  ---\n"
     ]
    }
   ],
   "source": [
    "mkdir(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../model/bertlinear_bbc_z0'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IR9OBn1qWFh",
    "outputId": "604a18c6-695c-4660-fbd2-ac6122993711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49129 entries, 0 to 49128\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       49129 non-null  object\n",
      " 1   1       49129 non-null  object\n",
      " 2   2       49129 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "T3q4rpX3qWFg",
    "outputId": "040d34b3-a8af-40d6-a8ff-535f16378817"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.441369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  2\n",
       "count  49129.000000\n",
       "mean       0.441369\n",
       "std        0.496556\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "Rkr43-q3rDw4"
   },
   "outputs": [],
   "source": [
    "cols_dict=['sentence_a', 'sentence_b', 'similarity']\n",
    "train.columns = cols_dict\n",
    "dev.columns = cols_dict\n",
    "test.columns = cols_dict[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "HVpo0p5YqWFg",
    "outputId": "cd2c124d-852e-405b-dbbb-bfd56b7505aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_a</th>\n",
       "      <th>sentence_b</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1560年10月，他在巴黎秘密会见了英国大使Nicolas Throckmorton，要求他...</td>\n",
       "      <td>1560年10月，他在巴黎秘密会见了英国大使尼古拉斯·斯罗克莫顿，并要求他通过英格兰返回苏格...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975年的NBA赛季 -  76赛季是全美篮球协会的第30个赛季。</td>\n",
       "      <td>1975-76赛季的全国篮球协会是NBA的第30个赛季。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>还有具体的讨论，公众形象辩论和项目讨论。</td>\n",
       "      <td>还有公开讨论，特定档案讨论和项目讨论。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>当可以保持相当的流速时，结果很高。</td>\n",
       "      <td>当可以保持可比较的流速时，结果很高。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>它是Akmola地区Zerendi区的所在地。</td>\n",
       "      <td>它是Akmola地区Zerendi区的所在地。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sentence_a  \\\n",
       "0  1560年10月，他在巴黎秘密会见了英国大使Nicolas Throckmorton，要求他...   \n",
       "1                 1975年的NBA赛季 -  76赛季是全美篮球协会的第30个赛季。   \n",
       "2                               还有具体的讨论，公众形象辩论和项目讨论。   \n",
       "3                                  当可以保持相当的流速时，结果很高。   \n",
       "4                            它是Akmola地区Zerendi区的所在地。   \n",
       "\n",
       "                                          sentence_b  similarity  \n",
       "0  1560年10月，他在巴黎秘密会见了英国大使尼古拉斯·斯罗克莫顿，并要求他通过英格兰返回苏格...           0  \n",
       "1                       1975-76赛季的全国篮球协会是NBA的第30个赛季。           1  \n",
       "2                                还有公开讨论，特定档案讨论和项目讨论。           0  \n",
       "3                                 当可以保持可比较的流速时，结果很高。           1  \n",
       "4                            它是Akmola地区Zerendi区的所在地。           1  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "3SsBlNUyFgN2",
    "outputId": "c9aa63fb-b264-4216-fc73-c1496198d7ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>len_a</th>\n",
       "      <th>len_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49129.000000</td>\n",
       "      <td>49129.000000</td>\n",
       "      <td>49129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.441369</td>\n",
       "      <td>44.659977</td>\n",
       "      <td>44.643469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496556</td>\n",
       "      <td>17.926405</td>\n",
       "      <td>17.844421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         similarity         len_a         len_b\n",
       "count  49129.000000  49129.000000  49129.000000\n",
       "mean       0.441369     44.659977     44.643469\n",
       "std        0.496556     17.926405     17.844421\n",
       "min        0.000000      7.000000      3.000000\n",
       "25%        0.000000     31.000000     32.000000\n",
       "50%        0.000000     42.000000     42.000000\n",
       "75%        1.000000     55.000000     55.000000\n",
       "max        1.000000    149.000000    149.000000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['len_a']=train['sentence_a'].map(lambda x: len(x))\n",
    "train['len_b']=train['sentence_b'].map(lambda x: len(x))\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "DF2MJ2qSqWFh",
    "outputId": "84f10ef1-8190-4519-c601-9e117b4ed82e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_a</th>\n",
       "      <th>sentence_b</th>\n",
       "      <th>similarity</th>\n",
       "      <th>len_a</th>\n",
       "      <th>len_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1560年10月，他在巴黎秘密会见了英国大使Nicolas Throckmorton，要求他...</td>\n",
       "      <td>1560年10月，他在巴黎秘密会见了英国大使尼古拉斯·斯罗克莫顿，并要求他通过英格兰返回苏格...</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975年的NBA赛季 -  76赛季是全美篮球协会的第30个赛季。</td>\n",
       "      <td>1975-76赛季的全国篮球协会是NBA的第30个赛季。</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>还有具体的讨论，公众形象辩论和项目讨论。</td>\n",
       "      <td>还有公开讨论，特定档案讨论和项目讨论。</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>当可以保持相当的流速时，结果很高。</td>\n",
       "      <td>当可以保持可比较的流速时，结果很高。</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>它是Akmola地区Zerendi区的所在地。</td>\n",
       "      <td>它是Akmola地区Zerendi区的所在地。</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sentence_a  \\\n",
       "0  1560年10月，他在巴黎秘密会见了英国大使Nicolas Throckmorton，要求他...   \n",
       "1                 1975年的NBA赛季 -  76赛季是全美篮球协会的第30个赛季。   \n",
       "2                               还有具体的讨论，公众形象辩论和项目讨论。   \n",
       "3                                  当可以保持相当的流速时，结果很高。   \n",
       "4                            它是Akmola地区Zerendi区的所在地。   \n",
       "\n",
       "                                          sentence_b  similarity  len_a  len_b  \n",
       "0  1560年10月，他在巴黎秘密会见了英国大使尼古拉斯·斯罗克莫顿，并要求他通过英格兰返回苏格...           0     56     51  \n",
       "1                       1975-76赛季的全国篮球协会是NBA的第30个赛季。           1     34     28  \n",
       "2                                还有公开讨论，特定档案讨论和项目讨论。           0     20     19  \n",
       "3                                 当可以保持可比较的流速时，结果很高。           1     17     18  \n",
       "4                            它是Akmola地区Zerendi区的所在地。           1     23     23  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if debug:\n",
    "    df_train = train.iloc[2000:20000,:].reset_index(drop = True)\n",
    "    df_val = train.iloc[:2000,:]\n",
    "else:\n",
    "    df_train = train\n",
    "    df_val = dev\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "2LqQCqKteonu",
    "outputId": "cc34c88b-adfb-4b09-ebf7-8a5407d15164"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_a</th>\n",
       "      <th>sentence_b</th>\n",
       "      <th>similarity</th>\n",
       "      <th>len_a</th>\n",
       "      <th>len_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>改变所选择的测定，改变细胞上的选择压力，因此可以改变转化细胞中使用的性质。</td>\n",
       "      <td>如果所选择的测定法变化，则选择性压力在细胞上改变，因此可以改变转化细胞中使用的特性。</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>办公室搬到德里米尔斯并于1871年2月重新建立，尽管Scio办公室于1871年9月更名。</td>\n",
       "      <td>办公室搬到了德里米尔斯，并于1871年2月重新命名，尽管Scio办公室于1871年9月重建。</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1844年，布鲁克林从波士顿吞并成为Pill Hill的一部分。</td>\n",
       "      <td>Pill Hill于1844年成为Brookline的一部分，当时它被波士顿吞并。</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>它们构成了西河的大部分人口和里奥内格罗河口上方的沃佩斯河上游。</td>\n",
       "      <td>它们构成了Xié河和Vaupés河口上方Rio Negro上游的大部分人口。</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>可以反转倾斜传感器，以便能够在GBA SP上正确播放。</td>\n",
       "      <td>可以播放倾斜传感器，以便能够在GBA SP上正确地反转它。</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentence_a  \\\n",
       "0         改变所选择的测定，改变细胞上的选择压力，因此可以改变转化细胞中使用的性质。   \n",
       "1  办公室搬到德里米尔斯并于1871年2月重新建立，尽管Scio办公室于1871年9月更名。   \n",
       "2              1844年，布鲁克林从波士顿吞并成为Pill Hill的一部分。   \n",
       "3               它们构成了西河的大部分人口和里奥内格罗河口上方的沃佩斯河上游。   \n",
       "4                   可以反转倾斜传感器，以便能够在GBA SP上正确播放。   \n",
       "\n",
       "                                       sentence_b  similarity  len_a  len_b  \n",
       "0      如果所选择的测定法变化，则选择性压力在细胞上改变，因此可以改变转化细胞中使用的特性。           1     37     42  \n",
       "1  办公室搬到了德里米尔斯，并于1871年2月重新命名，尽管Scio办公室于1871年9月重建。           0     44     46  \n",
       "2       Pill Hill于1844年成为Brookline的一部分，当时它被波士顿吞并。           0     32     41  \n",
       "3          它们构成了Xié河和Vaupés河口上方Rio Negro上游的大部分人口。           0     31     38  \n",
       "4                   可以播放倾斜传感器，以便能够在GBA SP上正确地反转它。           0     27     29  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"可以反转倾斜传感器，以便能够在GBA SP上正确播放。\"\n",
    "sent2 = \"可以播放倾斜传感器，以便能够在GBA SP上正确地反转它。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "re=tokenizer.encode_plus(sent1,sent2, padding='max_length', truncation=True, max_length=128, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 51])\n",
      "torch.Size([1, 51])\n",
      "torch.Size([1, 51])\n"
     ]
    }
   ],
   "source": [
    "print(re['input_ids'].size())\n",
    "print(re['token_type_ids'].size())\n",
    "print(re['attention_mask'].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "MNmqGnLJqWFh"
   },
   "outputs": [],
   "source": [
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, data, maxlen, with_labels=True, bert_model='bert-base-chinese'):\n",
    "        self.data = data\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model,output_loading_info = False)  \n",
    "        self.maxlen = maxlen\n",
    "        self.with_labels = with_labels \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Selecting sentence1 and sentence2 at the specified index in the data frame\n",
    "        sent1 = str(self.data.loc[index,'sentence_a'])\n",
    "        sent2 = str(self.data.loc[index,'sentence_b'])\n",
    "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
    "        encoded_input1 = self.tokenizer(sent1,sent2, padding='max_length', truncation=True, max_length=self.maxlen, return_tensors='pt')\n",
    "        #encoded_input1 = self.tokenizer.encode_plus(sent1,sent2, padding='max_length', truncation=True, max_length=self.maxlen, return_tensors='pt')\n",
    "        token_ids1 =  encoded_input1['input_ids'].squeeze(0) \n",
    "        attn_masks1 =  encoded_input1['attention_mask'].squeeze(0)  \n",
    "        token_type_ids1 =  encoded_input1['token_type_ids'].squeeze(0) \n",
    "\n",
    "        if self.with_labels:  # True if the dataset has labels\n",
    "            label = self.data.loc[index, 'similarity']\n",
    "            return token_ids1, attn_masks1, token_type_ids1, label\n",
    "        else:\n",
    "            return token_ids1, attn_masks1, token_type_ids1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "zFZkwPDNqWFi"
   },
   "outputs": [],
   "source": [
    "def val_lossF(net, device, criterion, dataloader):\n",
    "    net.eval()\n",
    "    mean_loss = 0\n",
    "    count = 0\n",
    "    true_labelss = []\n",
    "    list_val_outputs = []\n",
    "    val_metric = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for  i, (token_ids1, attn_masks1, token_type_ids1,labels) in enumerate(dataloader):\n",
    "            token_ids1, attn_masks1, token_type_ids1 = token_ids1.to(device), attn_masks1.to(device), token_type_ids1.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            val_output = net(token_ids1, attn_masks1, token_type_ids1)\n",
    "            mean_loss += criterion(val_output, labels.float()).item()\n",
    "            count += 1\n",
    "\n",
    "            val_outputs = val_output.sigmoid().cpu().numpy()\n",
    "            val_outputs = np.where(val_outputs>thres, 1, 0)\n",
    "            list_val_outputs += val_outputs.tolist()\n",
    "            labelss = labels.cpu().numpy()\n",
    "            true_labelss += labelss.tolist()  \n",
    "        val_metric = accuracy_score(list_val_outputs,true_labelss)       \n",
    "    return mean_loss / count, val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "ToUFshaakaYN"
   },
   "outputs": [],
   "source": [
    "class BertLinear(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.2, finetune_units=768, bert_model='bert-base-chinese', freeze_bert=False):\n",
    "        super(BertLinear, self).__init__()\n",
    "        self.bert_layer1 = BertModel.from_pretrained(bert_model,output_loading_info = False)\n",
    "        if bert_model == 'bert-base-chinese':\n",
    "            self.hidden_size = 768\n",
    "        elif bert_model == 'hfl/chinese-roberta-wwm-ext':\n",
    "            self.hidden_size = 768\n",
    "            \n",
    "        if freeze_bert:\n",
    "            for p in self.bert_layer.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.dropout0 = nn.Dropout(p=dropout_rate)\n",
    "        self.vec_layer = nn.Linear(self.hidden_size,1)\n",
    "        # self.cs_layer = nn.Sigmoid()\n",
    "        \n",
    "    def mean_pooling(self, all_vecs, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(all_vecs.size()).float()\n",
    "        sum_embeddings = torch.sum(all_vecs * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "    @autocast()\n",
    "    def forward(self,  token_ids1, attn_masks1, token_type_ids1):\n",
    "        vecs1 = self.bert_layer1(token_ids1, attn_masks1, token_type_ids1)\n",
    "        #Perform pooling. In this case, mean pooling\n",
    "        sent_embed1 = self.mean_pooling(vecs1[0], attn_masks1)\n",
    "        x1 = self.dropout0(sent_embed1)\n",
    "        x1 = self.vec_layer(x1)\n",
    "\n",
    "        return x1.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OYxoyFxqWFk",
    "outputId": "abe3aeeb-97e8-4a9e-a4a7-ac1f3272aabe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertLinear(\n",
       "  (bert_layer1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout0): Dropout(p=0.1, inplace=False)\n",
       "  (vec_layer): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "net = BertLinear(dropout_rate=dropout_rate, finetune_units=finetune_units,bert_model=bert_model,freeze_bert=freeze_bert)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.DataParallel(net, [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Akpv2SPRqWFl",
    "outputId": "9b06345b-8976-4189-9804-1ac6ac7df481"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [01:15<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete! Train Loss : 0.5763872265815735 , Validation Loss : 0.5882046461105347 , Validation Metric - Accuracy : 0.693 \n",
      "Best validation loss improved from inf to 0.5882046461105347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/90 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved in ep_1_val_loss_0.5882.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [01:18<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete! Train Loss : 0.46009939908981323 , Validation Loss : 0.5149914115667343 , Validation Metric - Accuracy : 0.743 \n",
      "Best validation loss improved from 0.5882046461105347 to 0.5149914115667343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/90 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved in ep_2_val_loss_0.515.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [01:20<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete! Train Loss : 0.4470978379249573 , Validation Loss : 0.5094869673252106 , Validation Metric - Accuracy : 0.7505 \n",
      "Best validation loss improved from 0.5149914115667343 to 0.5094869673252106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/90 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved in ep_3_val_loss_0.5095.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [01:20<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete! Train Loss : 0.3799962103366852 , Validation Loss : 0.5084242701530457 , Validation Metric - Accuracy : 0.762 \n",
      "Best validation loss improved from 0.5094869673252106 to 0.5084242701530457\n",
      "The model has been saved in ep_4_val_loss_0.5084.pt\n"
     ]
    }
   ],
   "source": [
    "train_set = LoadDataset(df_train, maxlen, bert_model)\n",
    "val_set = LoadDataset(df_val, maxlen, bert_model)\n",
    "train_loader = DataLoader(train_set, batch_size=bs)\n",
    "val_loader = DataLoader(val_set, batch_size=bs)\n",
    "\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "opti = AdamW(net.parameters(), lr=lr, weight_decay=1e-2)\n",
    "num_training_steps = epochs * len(train_loader)  # The total number of training steps\n",
    "lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps )\n",
    "scaler = GradScaler()\n",
    "\n",
    "best_loss = np.Inf\n",
    "best_ep = 1\n",
    "iters = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_metrics = []\n",
    "es_count = 0\n",
    "for ep in range(epochs):\n",
    "    for it, (token_ids1, attn_masks1, token_type_ids1,labels) in tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "        net.train()\n",
    "        \n",
    "        token_ids1, attn_masks1, token_type_ids1 = token_ids1.to(device), attn_masks1.to(device), token_type_ids1.to(device)\n",
    "        labels = labels.to(device)\n",
    "        opti.zero_grad()\n",
    "        with autocast():\n",
    "            output = net(token_ids1, attn_masks1, token_type_ids1)\n",
    "            loss = criterion(output, labels.float())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opti)\n",
    "        scaler.update()      \n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # if it % 100 == 0:\n",
    "        #     val_loss, val_metric = val_lossF(net, device, criterion, val_loader)  # Compute validation loss\n",
    "        #     print(\"it = {}, train_loss = {}, val_loss = {}, val_metric= {}\".format(it+1,loss,val_loss,val_metric))\n",
    "            \n",
    "    val_loss, val_metric = val_lossF(net, device, criterion, val_loader)  # Compute validation loss  \n",
    "    print(\"Epoch {} complete! Train Loss : {} , Validation Loss : {} , Validation Metric - Accuracy : {} \".format(ep+1, loss, val_loss, val_metric))\n",
    "    train_losses.append(loss)\n",
    "    val_losses.append(val_loss)  \n",
    "    val_metrics.append(val_metric)\n",
    "    if val_loss < best_loss:       \n",
    "        print(\"Best validation loss improved from {} to {}\".format(best_loss, val_loss))\n",
    "        net_copy = copy.deepcopy(net)  # save a copy of the model\n",
    "        best_loss = val_loss\n",
    "        best_ep = ep + 1\n",
    "        path_to_model='ep_{}_val_loss_{}.pt'.format(best_ep, round(best_loss, 4))\n",
    "        torch.save(net_copy.state_dict(), MODEL_SAVE_PATH + '/' + path_to_model)\n",
    "        print(\"The model has been saved in {}\".format(path_to_model))\n",
    "    # else:\n",
    "    #     es_count += 1\n",
    "    \n",
    "    # if early_stop and es_count>es_counts_MAX:\n",
    "    #     print('Early Stop Train in Epoch : {} '.format(ep+1))\n",
    "    #     break\n",
    "\n",
    "del loss\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "zOqc1UooqWFl",
    "outputId": "752c23c8-6141-42d8-875a-2764d7ab2e08"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  [tensor(0.5764, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), tensor(0.4601, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), tensor(0.4471, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), tensor(0.3800, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)]\n",
      "val loss =  [0.5882046461105347, 0.5149914115667343, 0.5094869673252106, 0.5084242701530457]\n",
      "val metric =  [0.693, 0.743, 0.7505, 0.762]\n"
     ]
    }
   ],
   "source": [
    "p1 = plt.plot(range(epochs),train_losses,'b--',label='train_loss')\n",
    "p2 = plt.plot(range(epochs),val_losses,'r--',label='validation_loss')\n",
    "p3 = plt.plot(range(epochs),val_metrics,'g--',label='validation_metric')\n",
    "plt.plot(range(epochs),train_losses,'bo-',range(epochs),val_losses,'r+-',range(epochs),val_metrics,'g^-')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss & metric')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('train loss = ', train_losses)\n",
    "print('val loss = ', val_losses)\n",
    "print('val metric = ', val_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../model/bertlinear_bbc_z0/ep_1_val_loss_0.269.pt'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_PATH + '/' + path_to_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0gMcF6BqWFm",
    "outputId": "7327a5db-d76b-4bc4-edf7-a07a5f3b8b18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "net = BertLinear(dropout_rate=dropout_rate, finetune_units=finetune_units,bert_model=bert_model)\n",
    "net = nn.DataParallel(net)\n",
    "net.load_state_dict(torch.load(MODEL_SAVE_PATH + '/' + path_to_model))\n",
    "net.to(device)\n",
    "\n",
    "test_set = LoadDataset(test, maxlen, with_labels=False, bert_model = bert_model)\n",
    "test_loader = DataLoader(test_set, batch_size=bs)\n",
    "\n",
    "net.eval()\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for token_ids1, attn_masks1, token_type_ids1 in tqdm(test_loader):\n",
    "        token_ids1, attn_masks1, token_type_ids1 = token_ids1.to(device), attn_masks1.to(device), token_type_ids1.to(device)\n",
    "        output = net(token_ids1, attn_masks1, token_type_ids1)\n",
    "        output = output.sigmoid().cpu().numpy()\n",
    "        output = np.where(output>thres, 1, 0)\n",
    "        results += output.tolist()\n",
    "\n",
    "test['similarity'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "YtOT6Np9xR6F",
    "outputId": "a8f399bd-f99d-4a4d-8500-e989a34fc5bc"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_csv() got an unexpected keyword argument 'delimiter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-fd7adb180025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_SAVE_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'dataset_path'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'preds.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: to_csv() got an unexpected keyword argument 'delimiter'"
     ]
    }
   ],
   "source": [
    "test.to_csv(MODEL_SAVE_PATH+'dataset_path'+'preds.tsv',sep='\\t')\n",
    "test.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../model/bertlinear_bbc_z0/dataset_path/preds.csv'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_PATH+'/dataset_path/'+'preds.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  prediction\n",
      "0         0           1\n",
      "1         1           0\n",
      "2         2           0\n",
      "3         3           0\n",
      "4         4           1\n",
      "...     ...         ...\n",
      "1995   1995           0\n",
      "1996   1996           1\n",
      "1997   1997           0\n",
      "1998   1998           0\n",
      "1999   1999           0\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "ls  = [\"index\" , \"prediction\"]\n",
    "df1=pd.DataFrame(columns=ls,index=None)#数据有三列，列名分别为one,two,three\n",
    "df1['index']=list(range(len(test)))\n",
    "df1['prediction']=test['similarity']\n",
    "print(df1)\n",
    "df1.to_csv('testcsv_new.csv',encoding='utf8',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Baidu千言-文本相似度-Baseline-BERTLinear.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
