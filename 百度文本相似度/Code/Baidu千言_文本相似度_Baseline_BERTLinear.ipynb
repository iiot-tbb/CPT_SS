{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Baidu千言-文本相似度-Baseline-BERTLinear.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DXlS3vq5iUL"
      },
      "source": [
        "\"\"\"\r\n",
        "记得每次训练更改新的model name用以分别保存模型参数文件\r\n",
        "可以通过dataset id来选择三个数据集中的一个\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "m_name = 'bertlinear_bbc_z0' # model name, bbc = 'bert-base-chinese\r\n",
        "dsid = 2 # dataset id = ['/bq_corpus','/lcqmc','/paws-x-zh'], 千言文本相似度比赛三个数据集是分开记分的"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSeiAr4AqWFe"
      },
      "source": [
        "debug = 1\n",
        "seed = 218\n",
        "\n",
        "# Model hyperparameter\n",
        "device = 'cuda'\n",
        "bert_model = 'bert-base-chinese' # 'hfl/chinese-roberta-wwm-ext'\n",
        "freeze_bert = False\n",
        "maxlen = 128\n",
        "finetune_units = 768\n",
        "dropout_rate = 0.1\n",
        "\n",
        "#　Train Hyperparameter\n",
        "bs = 16\n",
        "lr = 2e-5 #1e-3 #2e-5\n",
        "if debug:\n",
        "    epochs = 4\n",
        "    num_warmup_steps = 0\n",
        "else:\n",
        "    epochs = 8\n",
        "    num_warmup_steps = 2\n",
        "es_counts_MAX = 3\n",
        "# Postprocess hyperparameter\n",
        "thres = 0.5"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay5oQQtTrel4",
        "outputId": "7bc8c652-ea96-48c7-9f33-a006e06ca6e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGMGp4N0roaJ",
        "outputId": "57d5bf51-ea96-4f57-81f7-2b2d2df62114"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVEUNv1YqWFf"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "from scipy.spatial.distance import cosine\n",
        "import nltk\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "#float16和float32自动混合精度加速计算，官方文档：https://pytorch.org/docs/stable/amp.html\n",
        "from torch.cuda.amp import autocast\n",
        "from torch.cuda.amp import GradScaler"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajTqKw9qqWFf"
      },
      "source": [
        "def set_seed(seed = 42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    return seed\n",
        "\n",
        "seed = set_seed(seed)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6weZKnqqBLyp"
      },
      "source": [
        "# PATH Info\r\n",
        "CURR_PATH = os.getcwd()\r\n",
        "ROOT_PATH = CURR_PATH + '/drive/MyDrive/Baidu_Qianyan'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riZKNTNpqWFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0bfb4d2-3aaf-4406-e2c0-aa3058239cc9"
      },
      "source": [
        "def mkdir(path):\n",
        "\tfolder = os.path.exists(path)\n",
        "\tif not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
        "\t\tos.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
        "\t\tprint('---  New Model Folder: {}  ---'.format(m_name))\n",
        " \n",
        "\telse:\n",
        "\t\tprint('---  Model Dir Exsiting!  ---')\n",
        "\n",
        "def read_tsv(input_file):\n",
        "    with open(input_file,\"r\",encoding=\"utf-8\") as file:\n",
        "        lines = []\n",
        "        for line in file:\n",
        "            if len(line.strip().split(\"\\t\")) != 1:\n",
        "                lines.append(line.strip().split(\"\\t\"))\n",
        "        df = pd.DataFrame(lines)\n",
        "    return df\n",
        "\n",
        "DATASET_PATH = ['/bq_corpus','/lcqmc','/paws-x-zh']\n",
        "dataset_path = DATASET_PATH[dsid]\n",
        "ROOT_PATH = '/content/drive/MyDrive/Baidu_Qianyan'\n",
        "DATA_PATH = ['/train.tsv','/dev.tsv','/test.tsv']\n",
        "MODEL_SAVE_PATH = ROOT_PATH + '/model' + dataset_path + '/' + m_name \n",
        "mkdir(MODEL_SAVE_PATH)     \n",
        "\n",
        "train = pd.DataFrame()\n",
        "dev = pd.DataFrame()\n",
        "test = pd.DataFrame()\n",
        "for data_path in DATA_PATH:\n",
        "    PATH = ''.join([ROOT_PATH,dataset_path])\n",
        "    PATH = ''.join([PATH,data_path])\n",
        "    df = read_tsv(PATH)\n",
        "    if data_path == '/train.tsv':\n",
        "        train = pd.concat([train,df],axis = 0)\n",
        "    if data_path == '/dev.tsv':\n",
        "        dev = pd.concat([dev,df],axis = 0)\n",
        "    if data_path == '/test.tsv':\n",
        "        test = pd.concat([test,df],axis = 0)\n",
        "\n",
        "## bq_corpus在20746行的格式有问题，以下方法无法读取\n",
        "# train = pd.DataFrame()\n",
        "# for dataset_path in DATASET_PATH:\n",
        "#     print(dataset_path)\n",
        "#     for data_path in DATA_PATH:\n",
        "#         PATH = ''.join([ROOT_PATH,dataset_path])\n",
        "#         PATH = ''.join([PATH,data_path])\n",
        "#         read_df = pd.read_csv(PATH, header=0, delimiter='\\t')\n",
        "#         train.append(read_df)\n",
        "\n",
        "train[[2]] = train[[2]].astype(int)\n",
        "dev[[2]] = dev[[2]].astype(int)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---  Model Dir Exsiting!  ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IR9OBn1qWFh",
        "outputId": "604a18c6-695c-4660-fbd2-ac6122993711"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 49129 entries, 0 to 49128\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       49129 non-null  object\n",
            " 1   1       49129 non-null  object\n",
            " 2   2       49129 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "T3q4rpX3qWFg",
        "outputId": "040d34b3-a8af-40d6-a8ff-535f16378817"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>49129.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.441369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.496556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  2\n",
              "count  49129.000000\n",
              "mean       0.441369\n",
              "std        0.496556\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkr43-q3rDw4"
      },
      "source": [
        "cols_dict=['sentence_a', 'sentence_b', 'similarity']\r\n",
        "train.columns = cols_dict\r\n",
        "dev.columns = cols_dict\r\n",
        "test.columns = cols_dict[:2]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "HVpo0p5YqWFg",
        "outputId": "cd2c124d-852e-405b-dbbb-bfd56b7505aa"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_a</th>\n",
              "      <th>sentence_b</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1560年10月，他在巴黎秘密会见了英国大使Nicolas Throckmorton，要求他...</td>\n",
              "      <td>1560年10月，他在巴黎秘密会见了英国大使尼古拉斯·斯罗克莫顿，并要求他通过英格兰返回苏格...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1975年的NBA赛季 -  76赛季是全美篮球协会的第30个赛季。</td>\n",
              "      <td>1975-76赛季的全国篮球协会是NBA的第30个赛季。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>还有具体的讨论，公众形象辩论和项目讨论。</td>\n",
              "      <td>还有公开讨论，特定档案讨论和项目讨论。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>当可以保持相当的流速时，结果很高。</td>\n",
              "      <td>当可以保持可比较的流速时，结果很高。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>它是Akmola地区Zerendi区的所在地。</td>\n",
              "      <td>它是Akmola地区Zerendi区的所在地。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          sentence_a  ... similarity\n",
              "0  1560年10月，他在巴黎秘密会见了英国大使Nicolas Throckmorton，要求他...  ...          0\n",
              "1                 1975年的NBA赛季 -  76赛季是全美篮球协会的第30个赛季。  ...          1\n",
              "2                               还有具体的讨论，公众形象辩论和项目讨论。  ...          0\n",
              "3                                  当可以保持相当的流速时，结果很高。  ...          1\n",
              "4                            它是Akmola地区Zerendi区的所在地。  ...          1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "3SsBlNUyFgN2",
        "outputId": "c9aa63fb-b264-4216-fc73-c1496198d7ca"
      },
      "source": [
        "train['len_a']=train['sentence_a'].map(lambda x: len(x))\r\n",
        "train['len_b']=train['sentence_b'].map(lambda x: len(x))\r\n",
        "train.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>len_a</th>\n",
              "      <th>len_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>49129.000000</td>\n",
              "      <td>49129.000000</td>\n",
              "      <td>49129.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.441369</td>\n",
              "      <td>44.659977</td>\n",
              "      <td>44.643469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.496556</td>\n",
              "      <td>17.926405</td>\n",
              "      <td>17.844421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>32.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>149.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         similarity         len_a         len_b\n",
              "count  49129.000000  49129.000000  49129.000000\n",
              "mean       0.441369     44.659977     44.643469\n",
              "std        0.496556     17.926405     17.844421\n",
              "min        0.000000      7.000000      3.000000\n",
              "25%        0.000000     31.000000     32.000000\n",
              "50%        0.000000     42.000000     42.000000\n",
              "75%        1.000000     55.000000     55.000000\n",
              "max        1.000000    149.000000    149.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "DF2MJ2qSqWFh",
        "outputId": "84f10ef1-8190-4519-c601-9e117b4ed82e"
      },
      "source": [
        "if debug:\n",
        "    df_train = train.iloc[2000:20000,:].reset_index(drop = True)\n",
        "    df_val = train.iloc[:2000,:]\n",
        "else:\n",
        "    df_train = train\n",
        "    df_val = dev\n",
        "df_val.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_a</th>\n",
              "      <th>sentence_b</th>\n",
              "      <th>similarity</th>\n",
              "      <th>len_a</th>\n",
              "      <th>len_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1560年10月，他在巴黎秘密会见了英国大使Nicolas Throckmorton，要求他...</td>\n",
              "      <td>1560年10月，他在巴黎秘密会见了英国大使尼古拉斯·斯罗克莫顿，并要求他通过英格兰返回苏格...</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1975年的NBA赛季 -  76赛季是全美篮球协会的第30个赛季。</td>\n",
              "      <td>1975-76赛季的全国篮球协会是NBA的第30个赛季。</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>还有具体的讨论，公众形象辩论和项目讨论。</td>\n",
              "      <td>还有公开讨论，特定档案讨论和项目讨论。</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>当可以保持相当的流速时，结果很高。</td>\n",
              "      <td>当可以保持可比较的流速时，结果很高。</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>它是Akmola地区Zerendi区的所在地。</td>\n",
              "      <td>它是Akmola地区Zerendi区的所在地。</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          sentence_a  ... len_b\n",
              "0  1560年10月，他在巴黎秘密会见了英国大使Nicolas Throckmorton，要求他...  ...    51\n",
              "1                 1975年的NBA赛季 -  76赛季是全美篮球协会的第30个赛季。  ...    28\n",
              "2                               还有具体的讨论，公众形象辩论和项目讨论。  ...    19\n",
              "3                                  当可以保持相当的流速时，结果很高。  ...    18\n",
              "4                            它是Akmola地区Zerendi区的所在地。  ...    23\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "2LqQCqKteonu",
        "outputId": "cc34c88b-adfb-4b09-ebf7-8a5407d15164"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_a</th>\n",
              "      <th>sentence_b</th>\n",
              "      <th>similarity</th>\n",
              "      <th>len_a</th>\n",
              "      <th>len_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>改变所选择的测定，改变细胞上的选择压力，因此可以改变转化细胞中使用的性质。</td>\n",
              "      <td>如果所选择的测定法变化，则选择性压力在细胞上改变，因此可以改变转化细胞中使用的特性。</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>办公室搬到德里米尔斯并于1871年2月重新建立，尽管Scio办公室于1871年9月更名。</td>\n",
              "      <td>办公室搬到了德里米尔斯，并于1871年2月重新命名，尽管Scio办公室于1871年9月重建。</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1844年，布鲁克林从波士顿吞并成为Pill Hill的一部分。</td>\n",
              "      <td>Pill Hill于1844年成为Brookline的一部分，当时它被波士顿吞并。</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>它们构成了西河的大部分人口和里奥内格罗河口上方的沃佩斯河上游。</td>\n",
              "      <td>它们构成了Xié河和Vaupés河口上方Rio Negro上游的大部分人口。</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>可以反转倾斜传感器，以便能够在GBA SP上正确播放。</td>\n",
              "      <td>可以播放倾斜传感器，以便能够在GBA SP上正确地反转它。</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     sentence_a  ... len_b\n",
              "0         改变所选择的测定，改变细胞上的选择压力，因此可以改变转化细胞中使用的性质。  ...    42\n",
              "1  办公室搬到德里米尔斯并于1871年2月重新建立，尽管Scio办公室于1871年9月更名。  ...    46\n",
              "2              1844年，布鲁克林从波士顿吞并成为Pill Hill的一部分。  ...    41\n",
              "3               它们构成了西河的大部分人口和里奥内格罗河口上方的沃佩斯河上游。  ...    38\n",
              "4                   可以反转倾斜传感器，以便能够在GBA SP上正确播放。  ...    29\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNmqGnLJqWFh"
      },
      "source": [
        "class LoadDataset(Dataset):\n",
        "    def __init__(self, data, maxlen, with_labels=True, bert_model='bert-base-chinese'):\n",
        "        self.data = data\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(bert_model,output_loading_info = False)  \n",
        "        self.maxlen = maxlen\n",
        "        self.with_labels = with_labels \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Selecting sentence1 and sentence2 at the specified index in the data frame\n",
        "        sent1 = str(self.data.loc[index,'sentence_a'])\n",
        "        sent2 = str(self.data.loc[index,'sentence_b'])\n",
        "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
        "        encoded_input1 = self.tokenizer(sent1,sent2, padding='max_length', truncation=True, max_length=self.maxlen, return_tensors='pt')\n",
        "        token_ids1 =  encoded_input1['input_ids'].squeeze(0) \n",
        "        attn_masks1 =  encoded_input1['attention_mask'].squeeze(0)  \n",
        "        token_type_ids1 =  encoded_input1['token_type_ids'].squeeze(0) \n",
        "\n",
        "        if self.with_labels:  # True if the dataset has labels\n",
        "            label = self.data.loc[index, 'similarity']\n",
        "            return token_ids1, attn_masks1, token_type_ids1, label\n",
        "        else:\n",
        "            return token_ids1, attn_masks1, token_type_ids1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFZkwPDNqWFi"
      },
      "source": [
        "def val_lossF(net, device, criterion, dataloader):\n",
        "    net.eval()\n",
        "    mean_loss = 0\n",
        "    count = 0\n",
        "    true_labelss = []\n",
        "    list_val_outputs = []\n",
        "    val_metric = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for  i, (token_ids1, attn_masks1, token_type_ids1,labels) in enumerate(dataloader):\n",
        "            token_ids1, attn_masks1, token_type_ids1 = token_ids1.to(device), attn_masks1.to(device), token_type_ids1.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            val_output = net(token_ids1, attn_masks1, token_type_ids1)\n",
        "            mean_loss += criterion(val_output, labels.float()).item()\n",
        "            count += 1\n",
        "\n",
        "            val_outputs = val_output.sigmoid().cpu().numpy()\n",
        "            val_outputs = np.where(val_outputs>thres, 1, 0)\n",
        "            list_val_outputs += val_outputs.tolist()\n",
        "            labelss = labels.cpu().numpy()\n",
        "            true_labelss += labelss.tolist()  \n",
        "        val_metric = accuracy_score(list_val_outputs,true_labelss)       \n",
        "    return mean_loss / count, val_metric"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToUFshaakaYN"
      },
      "source": [
        "class BertLinear(nn.Module):\r\n",
        "    def __init__(self, dropout_rate=0.2, finetune_units=768, bert_model='bert-base-chinese', freeze_bert=False):\r\n",
        "        super(BertLinear, self).__init__()\r\n",
        "        self.bert_layer1 = BertModel.from_pretrained(bert_model,output_loading_info = False)\r\n",
        "        if bert_model == 'bert-base-chinese':\r\n",
        "            self.hidden_size = 768\r\n",
        "        elif bert_model == 'hfl/chinese-roberta-wwm-ext':\r\n",
        "            self.hidden_size = 768\r\n",
        "            \r\n",
        "        if freeze_bert:\r\n",
        "            for p in self.bert_layer.parameters():\r\n",
        "                p.requires_grad = False\r\n",
        "\r\n",
        "        self.dropout0 = nn.Dropout(p=dropout_rate)\r\n",
        "        self.vec_layer = nn.Linear(self.hidden_size,1)\r\n",
        "        # self.cs_layer = nn.Sigmoid()\r\n",
        "        \r\n",
        "    def mean_pooling(self, all_vecs, attention_mask):\r\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(all_vecs.size()).float()\r\n",
        "        sum_embeddings = torch.sum(all_vecs * input_mask_expanded, 1)\r\n",
        "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\r\n",
        "        return sum_embeddings / sum_mask\r\n",
        "\r\n",
        "    @autocast()\r\n",
        "    def forward(self,  token_ids1, attn_masks1, token_type_ids1):\r\n",
        "        vecs1 = self.bert_layer1(token_ids1, attn_masks1, token_type_ids1)\r\n",
        "        #Perform pooling. In this case, mean pooling\r\n",
        "        sent_embed1 = self.mean_pooling(vecs1[0], attn_masks1)\r\n",
        "        x1 = self.dropout0(sent_embed1)\r\n",
        "        x1 = self.vec_layer(x1)\r\n",
        "\r\n",
        "        return x1.squeeze(-1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OYxoyFxqWFk",
        "outputId": "abe3aeeb-97e8-4a9e-a4a7-ac1f3272aabe"
      },
      "source": [
        "device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
        "net = BertLinear(dropout_rate=dropout_rate, finetune_units=finetune_units,bert_model=bert_model,freeze_bert=freeze_bert)\n",
        "net.to(device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertLinear(\n",
              "  (bert_layer1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout0): Dropout(p=0.1, inplace=False)\n",
              "  (vec_layer): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akpv2SPRqWFl",
        "outputId": "9b06345b-8976-4189-9804-1ac6ac7df481"
      },
      "source": [
        "train_set = LoadDataset(df_train, maxlen, bert_model)\n",
        "val_set = LoadDataset(df_val, maxlen, bert_model)\n",
        "train_loader = DataLoader(train_set, batch_size=bs)\n",
        "val_loader = DataLoader(val_set, batch_size=bs)\n",
        "\n",
        "#criterion = nn.MSELoss()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "opti = AdamW(net.parameters(), lr=lr, weight_decay=1e-2)\n",
        "num_training_steps = epochs * len(train_loader)  # The total number of training steps\n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps )\n",
        "scaler = GradScaler()\n",
        "\n",
        "best_loss = np.Inf\n",
        "best_ep = 1\n",
        "iters = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_metrics = []\n",
        "es_count = 0\n",
        "for ep in range(epochs):\n",
        "    for it, (token_ids1, attn_masks1, token_type_ids1,labels) in tqdm(enumerate(train_loader), total = len(train_loader)):\n",
        "        net.train()\n",
        "        \n",
        "        token_ids1, attn_masks1, token_type_ids1 = token_ids1.to(device), attn_masks1.to(device), token_type_ids1.to(device)\n",
        "        labels = labels.to(device)\n",
        "        opti.zero_grad()\n",
        "        with autocast():\n",
        "            output = net(token_ids1, attn_masks1, token_type_ids1)\n",
        "            loss = criterion(output, labels.float())\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opti)\n",
        "        scaler.update()      \n",
        "        lr_scheduler.step()\n",
        "        \n",
        "        # if it % 100 == 0:\n",
        "        #     val_loss, val_metric = val_lossF(net, device, criterion, val_loader)  # Compute validation loss\n",
        "        #     print(\"it = {}, train_loss = {}, val_loss = {}, val_metric= {}\".format(it+1,loss,val_loss,val_metric))\n",
        "            \n",
        "    val_loss, val_metric = val_lossF(net, device, criterion, val_loader)  # Compute validation loss  \n",
        "    print(\"Epoch {} complete! Train Loss : {} , Validation Loss : {} , Validation Metric - Accuracy : {} \".format(ep+1, loss, val_loss, val_metric))\n",
        "    train_losses.append(loss)\n",
        "    val_losses.append(val_loss)  \n",
        "    val_metrics.append(val_metric)\n",
        "    if val_loss < best_loss:       \n",
        "        print(\"Best validation loss improved from {} to {}\".format(best_loss, val_loss))\n",
        "        net_copy = copy.deepcopy(net)  # save a copy of the model\n",
        "        best_loss = val_loss\n",
        "        best_ep = ep + 1\n",
        "        path_to_model='ep_{}_val_loss_{}.pt'.format(best_ep, round(best_loss, 4))\n",
        "        torch.save(net_copy.state_dict(), MODEL_SAVE_PATH + '/' + path_to_model)\n",
        "        print(\"The model has been saved in {}\".format(path_to_model))\n",
        "    # else:\n",
        "    #     es_count += 1\n",
        "    \n",
        "    # if early_stop and es_count>es_counts_MAX:\n",
        "    #     print('Early Stop Train in Epoch : {} '.format(ep+1))\n",
        "    #     break\n",
        "\n",
        "del loss\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1125/1125 [03:01<00:00,  6.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 complete! Train Loss : 0.5246972441673279 , Validation Loss : 0.4670320301055908 , Validation Metric - Accuracy : 0.766 \n",
            "Best validation loss improved from inf to 0.4670320301055908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1125 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The model has been saved in ep_1_val_loss_0.467.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1125/1125 [03:01<00:00,  6.19it/s]\n",
            "  0%|          | 1/1125 [00:00<02:55,  6.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 complete! Train Loss : 0.20122851431369781 , Validation Loss : 0.4844836220741272 , Validation Metric - Accuracy : 0.7815 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1125/1125 [03:01<00:00,  6.20it/s]\n",
            "  0%|          | 1/1125 [00:00<02:55,  6.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 complete! Train Loss : 0.25645771622657776 , Validation Loss : 0.5091198494434357 , Validation Metric - Accuracy : 0.7805 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1125/1125 [03:01<00:00,  6.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 complete! Train Loss : 0.07256873697042465 , Validation Loss : 0.5672451105117798 , Validation Metric - Accuracy : 0.7865 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOqc1UooqWFl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "752c23c8-6141-42d8-875a-2764d7ab2e08"
      },
      "source": [
        "p1 = plt.plot(range(epochs),train_losses,'b--',label='train_loss')\n",
        "p2 = plt.plot(range(epochs),val_losses,'r--',label='validation_loss')\n",
        "p3 = plt.plot(range(epochs),val_metrics,'g--',label='validation_metric')\n",
        "plt.plot(range(epochs),train_losses,'bo-',range(epochs),val_losses,'r+-',range(epochs),val_metrics,'g^-')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss & metric')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print('train loss = ', train_losses)\n",
        "print('val loss = ', val_losses)\n",
        "print('val metric = ', val_metrics)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "train loss =  [tensor(0.5247, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), tensor(0.2012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), tensor(0.2565, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), tensor(0.0726, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)]\n",
            "val loss =  [0.4670320301055908, 0.4844836220741272, 0.5091198494434357, 0.5672451105117798]\n",
            "val metric =  [0.766, 0.7815, 0.7805, 0.7865]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0gMcF6BqWFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7327a5db-d76b-4bc4-edf7-a07a5f3b8b18"
      },
      "source": [
        "net = BertLinear(dropout_rate=dropout_rate, finetune_units=finetune_units,bert_model=bert_model)\n",
        "net.load_state_dict(torch.load(MODEL_SAVE_PATH + '/' + path_to_model))\n",
        "net.to(device)\n",
        "\n",
        "test_set = LoadDataset(test, maxlen, with_labels=False, bert_model = bert_model)\n",
        "test_loader = DataLoader(test_set, batch_size=bs)\n",
        "\n",
        "net.eval()\n",
        "results = []\n",
        "with torch.no_grad():\n",
        "    for token_ids1, attn_masks1, token_type_ids1 in tqdm(test_loader):\n",
        "        token_ids1, attn_masks1, token_type_ids1 = token_ids1.to(device), attn_masks1.to(device), token_type_ids1.to(device)\n",
        "        output = net(token_ids1, attn_masks1, token_type_ids1)\n",
        "        output = output.sigmoid().cpu().numpy()\n",
        "        output = np.where(output>thres, 1, 0)\n",
        "        results += output.tolist()\n",
        "\n",
        "test['similarity'] = results"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [00:07<00:00, 17.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtOT6Np9xR6F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "a8f399bd-f99d-4a4d-8500-e989a34fc5bc"
      },
      "source": [
        "test.to_csv(MODEL_SAVE_PATH+'dataset_path'+'preds.csv')\r\n",
        "test.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_a</th>\n",
              "      <th>sentence_b</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2005 年末至 2009 年期间是例外，当时他效力于瑞典的卡斯塔德联队、塞尔维亚的查查克足...</td>\n",
              "      <td>例外情况发生于 2005 年末至 2009 年期间，当时他效力于瑞典的卡斯塔德联队、塞尔维亚...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tabaci 河是罗马尼亚 Leurda 河的支流。</td>\n",
              "      <td>Leurda 河是罗马尼亚境内 Tabaci 河的一条支流。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1993 年，他为 A 级的坎恩郡美洲狮队和 AA 级的波特兰海狗队效力。</td>\n",
              "      <td>1993 年，他为 A 级球队波特兰海狗队和 AA 级球队凯恩县美洲狮队效力。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Winarsky 是 IEEE、Phi Beta Kappa、ACM 和 Sigma Xi ...</td>\n",
              "      <td>温那斯基是 ACM、IEEE、Phi Beta Kappa 和 Sigma Xi 的成员。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1938 年，他成为英埃苏丹的政府人类学家，并领导对努巴的实地考察工作。</td>\n",
              "      <td>1938 年，他成为英埃苏丹政府的人类学家，并与努巴一起从事野外工作。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          sentence_a  ... similarity\n",
              "0  2005 年末至 2009 年期间是例外，当时他效力于瑞典的卡斯塔德联队、塞尔维亚的查查克足...  ...          1\n",
              "1                         Tabaci 河是罗马尼亚 Leurda 河的支流。  ...          1\n",
              "2              1993 年，他为 A 级的坎恩郡美洲狮队和 AA 级的波特兰海狗队效力。  ...          0\n",
              "3  Winarsky 是 IEEE、Phi Beta Kappa、ACM 和 Sigma Xi ...  ...          1\n",
              "4               1938 年，他成为英埃苏丹的政府人类学家，并领导对努巴的实地考察工作。  ...          1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}